{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial (Simple DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# Set backend of Keras to Tensorflow not Theano\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, pooling\n",
    "from keras.utils import np_utils\n",
    "# MNIST DATA Module\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load MNIST Data\n",
    "# if you don't have MNIST, it would be downloaded\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Shape of MNIST input data of Training Set\n",
    "print(X_train.shape)\n",
    "\n",
    "# Reshaping of input data for training with MLP(Multi-Layer Perceptron)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[-2] * X_train.shape[-1]) # 60000, 28 * 28\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[-2] * X_test.shape[-1]) # 10000, 28 * 28\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modifying type of inputs for train; uint8 -> float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization with inputs. Max value 255; Min value 0\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# One hot encoding with labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s - loss: 0.8402 - acc: 0.7532     \n",
      "['loss', 'acc']\n",
      "[0.3815098744392395, 0.90229999999999999]\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization\n",
    "model = Sequential()\n",
    "\n",
    "## Dense Layer 784 -> 128 node, Activation Function = ReLU\n",
    "# activation: string, [*relu, sigmoid, tanh]\n",
    "model.add(Dense(128, input_dim=784, activation='relu'))\n",
    "\n",
    "# Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Dense Layer 128 -> 10 node, Activation Function = Softmax => Output\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "## Loss Function = Cross Entropy, Optimizer = Adam Optimizer\n",
    "# optimizer: [adam, rmsprop, adagrad, adadelta, sgd, adamax, *nadam]\n",
    "# Default Learning Rate: adam=0.001, rmsprop=0.001, adagrad=0.01, adadelta=1.0, sgd=0.01, adamax=0.002, nadam=0.002\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "## Model Train\n",
    "# Input: X_train, Label: Y_train\n",
    "# Batch size = 32 ; don't increase this too large. It affects GPU Memory Usage\n",
    "# verbose: 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=1, verbose=1)\n",
    "\n",
    "# Test Set Accuracy Evaluation\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.40610317567586901, 0.89421666666666666]\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy Evaluation\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
